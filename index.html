<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>BPH - Neutral Frontend</title>

  <style>
    /* RESET */
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    /* BODY STYLE */
    body {
      width: 100%;
      height: 100vh;
      font-family: Arial, sans-serif;
      overflow: hidden; /* Hide scrollbars */
      color: #333; /* Neutral text color */
      background: linear-gradient(135deg, #ECE9E6, #FFFFFF);
      background-size: 400% 400%;
      animation: gradientBG 15s ease infinite;
      display: flex;
      justify-content: center;
      align-items: center;
      text-align: center;
      position: relative;
    }

    @keyframes gradientBG {
      0%   { background-position: 0% 50%; }
      50%  { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }

    /* FULLSCREEN TAP AREA */
    .tap-area {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      cursor: pointer;
      display: flex;
      justify-content: center;
      align-items: center;
      flex-direction: column;
    }

    .tap-area h1 {
      font-size: 1.5rem;
      padding: 1rem;
      background-color: rgba(0, 0, 0, 0.05);
      border-radius: 12px;
      color: #333;
      margin: 0;
    }

    /* DESCRIPTION BOX */
    .description {
      position: fixed;
      bottom: 5%;
      left: 50%;
      transform: translateX(-50%);
      background: rgba(0, 0, 0, 0.1);
      padding: 0.75rem 1rem;
      border-radius: 8px;
      display: none;
      font-size: 1rem;
      color: #333;
      z-index: 999;
    }
  </style>
</head>
<body>
    <div class="flex">
        <div class="camera">
            <video autoplay muted playsinline id="video">Video stream not available.</video>
        </div>
        <canvas style="display: none;" id="canvas"> </canvas>
        <div class="output">
            <img id="photo" alt="The screen capture will appear in this box." />
        </div>
    </div>
    

  <!-- TAPPABLE AREA -->
  <div class="tap-area" id="tap-area"
     style="justify-content: flex-start; align-items: center; padding-top: 2rem;">
  <h1>Tap anywhere to analyze your surroundings</h1>
</div>

  <!-- DESCRIPTION BOX -->
  <div class="description" id="description">Processing...</div>

  <!-- SCRIPTS -->
  <script>
    // API Key (hardcoded for simplicity; consider a secure way to handle this)
    const apiKey = "AIzaSyANglJxogyArZcrQap-kHivX0_sdDfAsXU";

    // Respond function adapted for the browser
    async function respond(base64Image) {
      const request = {
        contents: [
          {
            parts: [
              {
                text: `You are assisting a visually impaired person by describing their surroundings based on the image provided. The purpose is to give actionable and helpful guidance.
                
                Consider the following:

                1. Identify key obstacles, such as cars, poles, people, or walls, and their relative positions (e.g., "ahead," "left," "right", distance in feet, etc).

                2. If a crosswalk is present, indicate whether it is safe to cross, considering any approaching vehicles.

                3. Mention other important details that could impact movement or navigation, such as stairs, open doors, or uneven terrain.

                4. Keep the response concise, in 1-2 sentences, using simple and clear language.`,
              },
              {
                inline_data: {
                  mime_type: "image/jpeg",
                  data: base64Image,
                },
              },
            ],
          },
        ],
      };

      try {
        const response = await fetch(
          `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${apiKey}`,
          {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify(request),
          }
        );

        if (!response.ok) {
          throw new Error(`API Request failed: ${response.statusText}`);
        }

        const result = await response.json();
        return result.contents[0].parts[0].text;
      } catch (error) {
        console.error("Error:", error.message);
        return "Failed to generate a response.";
      }
    }


    // // Reference to HTML elements
    const tapArea = document.getElementById('tap-area');
    const description = document.getElementById('description');

    // Click event listener
    tapArea.addEventListener('click', async () => {
      description.textContent = "Processing...";
      description.style.display = 'block';
      //const base64Image = await loadBase64FromFile(); // Load Base64 dynamically
      const responseText = await respond(base64Image);
      description.textContent = responseText;


      // try {
      //   // Call the `respond` function and get the AI-generated response

      //   // description.textContent = "Hello World";

      //   // Speak the response out loud
      //   const utterance = new SpeechSynthesisUtterance(responseText);
      //   window.speechSynthesis.speak(utterance);
      // } catch (error) {
      //   description.textContent = "Error processing the request.";
      //   console.error("Error:", error);
      // }

      // Hide the description after 5 seconds
      setTimeout(() => {
        description.style.display = 'none';
      }, 5000);
    });
  </script>
  <script src="./js/camera.js"></script>
</body>
</html>

